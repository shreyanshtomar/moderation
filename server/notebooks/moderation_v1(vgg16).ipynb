{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "moderation_v1(vgg16).ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyanshtomar/moderation/blob/shreyansh_dev/server/notebooks/moderation_v1(vgg16).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX1bhSTjWHgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import cv2                \n",
        "from glob import glob\n",
        "from io import open\n",
        "import json\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, os.path, random\n",
        "from PIL import Image\n",
        "import requests\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xo8cr93-tgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b42e50c9-ee27-4b2d-8f44-8cc20ddf6f63"
      },
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE-LwAndCt8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/'\n",
        "train_dir = os.path.join(data_dir, 'train/')\n",
        "test_dir = os.path.join(data_dir, 'test/')\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['nsfw','sfw']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg8C7TzpDJi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1d739935-061e-4634-966c-bd509e5d7d33"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                            transforms.RandomResizedCrop(size=224),                                   \n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "test_transforms = transforms.Compose([                                  \n",
        "                            transforms.Resize(256),\n",
        "                            transforms.CenterCrop(224),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "# print out some data stats\n",
        "print('Num training images: ', len(train_data))\n",
        "print('Num test images: ', len(test_data))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num training images:  103518\n",
            "Num test images:  3365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z74c-DT1EBYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dataloader parameters\n",
        "batch_size = 128\n",
        "num_workers=0\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, shuffle=True)\n",
        "loaders_scratch = {\n",
        "    'train': train_loader,\n",
        "    'test': test_loader\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TWScgqjsKEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder and decoder to convert classes into integer\n",
        "decoder = {}\n",
        "for i in range(len(classes)):\n",
        "    decoder[classes[i]] = i\n",
        "encoder = {}\n",
        "for i in range(len(classes)):\n",
        "    encoder[i] = classes[i]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvbNylTdsnDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inv_normalize =  transforms.Normalize(\n",
        "    mean=[-0.4302/0.2361, -0.4575/0.2347, -0.4539/0.2432],\n",
        "    std=[1/0.2361, 1/0.2347, 1/0.2432]\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZURFwRr_5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#plotting rondom images from dataset\n",
        "n_figures = 9 # Number of images in plot\n",
        "def class_plot( data , encoder ,inv_normalizen_figures = 12):\n",
        "    n_row = int(n_figures/3)\n",
        "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=3)\n",
        "    for ax in axes.flatten():\n",
        "        a = random.randint(0,len(data))\n",
        "        (image,label) = data[a]\n",
        "        label = int(label)\n",
        "        l = encoder[label]\n",
        "        image = inv_normalize(image)\n",
        "        image = image.numpy().transpose(1,2,0)\n",
        "        im = ax.imshow(image)\n",
        "        ax.set_title(l)\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "class_plot(train_data,encoder,inv_normalize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un6P_1F8EG7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = models.vgg16(pretrained=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypffh-IQFGpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze training for all \"features\" layers\n",
        "for param in net.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuyk-qADFLJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30bf9432-49d6-4c3b-99b3-fa1bb555b310"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "n_inputs = net.classifier[6].in_features\n",
        "\n",
        "# add last linear layer\n",
        "# new layers automatically have requires_grad = True\n",
        "last_layer = nn.Linear(n_inputs, len(classes))\n",
        "\n",
        "net.classifier[6] = last_layer\n",
        "\n",
        "# if GPU is available, move the model to GPU\n",
        "if train_on_gpu:\n",
        "    net.cuda()\n",
        "\n",
        "# check to see that your last layer produces the expected number of outputs\n",
        "print(net.classifier[6].out_features)\n",
        "#print(net)\n",
        "\n",
        "# after completing your model, if GPU is available, move the model to GPU\n",
        "if train_on_gpu:\n",
        "    net.cuda()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYOjWpfdG6WW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Specifying Loss & Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aowSRIgvGx2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
        "optimizer = optim.SGD(net.classifier.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5pBMdSCHBYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 4\n",
        "print_every = 10\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
        "        data_, target_ = data_.to(device), target_.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = net(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 20 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        for data_t, target_t in (test_loader):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = net(data_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(test_loader))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(net.state_dict(), 'vgg16a.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    net.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OFeAMdf3iR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9inxX_4UMb1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e48867d0-aebc-4d4f-e9c3-a5a0491c7132"
      },
      "source": [
        "def test(loaders, model, criterion, train_on_gpu):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2f%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_scratch, net, criterion, train_on_gpu)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.149996\n",
            "\n",
            "\n",
            "Test Accuracy: 94.442793% (3178.000000/3365.000000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8auqEd60exz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def load_input_image(img_path):    \n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n",
        "                                     transforms.ToTensor(), \n",
        "                                     standard_normalization])\n",
        "\n",
        "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
        "    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n",
        "    return image"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaao8vU16wmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaders_transfer = loaders_scratch.copy()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS1LX-8E6cL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
        "\n",
        "\n",
        "def predict_nsfw(model, class_names, img_path):\n",
        "    # load the image and return the predicted breed\n",
        "    img = load_input_image(img_path)\n",
        "    model = model.cpu()\n",
        "    model.eval()\n",
        "    idx = torch.argmax(model(img))\n",
        "    return class_names[idx]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkmZmlrw_Qeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4lHvyofAv-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), 'vgg16_c.pth')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmY1KssyA9o1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "673e6a6a-e4d4-416b-9c16-e78e96777a92"
      },
      "source": [
        "net.load_state_dict(torch.load('vgg16_c.pth'))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKZIL7QQ_Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHZLoR7Bldm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, train_on_gpu):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2f%% (%2d/%2d)' % (100. * correct / total, correct, total))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyH1uRboAaDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "18a5bf8f-60ef-43fd-ec68-5ea4a5644587"
      },
      "source": [
        "# call test function    \n",
        "test(loaders_transfer, net, criterion, train_on_gpu)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.147624\n",
            "\n",
            "\n",
            "Test Accuracy: 94.650817% (3185/3365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSmRD-EAeWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_matrix(true,pred):\n",
        "    precision = metrics.precision_score(true,pred,average='macro')\n",
        "    recall = metrics.recall_score(true,pred,average='macro')\n",
        "    accuracy = metrics.accuracy_score(true,pred)\n",
        "    f1_score = metrics.f1_score(true,pred,average='macro')\n",
        "    print('Confusion Matrix:\\n',metrics.confusion_matrix(true, pred))\n",
        "    print('Precision: {} Recall: {}, Accuracy: {}: ,f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmGM3EzpBs05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp '/content/vgg16_c.pth' '/content/drive/My Drive/phase_2_chkpts'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kc3SeGJQuZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xswc10l0DcGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5a8e3d48-77cb-4787-9a38-53c5a91bd37b"
      },
      "source": [
        "nb_classes = 2\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(loaders_transfer['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1600.,   69.],\n",
            "        [ 127., 1569.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A86euVfSGIgv",
        "colab_type": "text"
      },
      "source": [
        "### per-class confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqG0iklFaOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8916d8cc-7168-46b7-c98f-398c41f9e914"
      },
      "source": [
        "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.9605, 0.9228])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pjJEQ1wHkFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fHkElX7H0FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix.numpy()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNDzyPaGJamV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(data=cm, index=[\"nsfw\", \"sfw\"], columns=[\"nsfw\", \"sfw\"])"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-MbTki-Js6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4b718629-72bb-462b-cd9b-8f82947af4f1"
      },
      "source": [
        "sns.heatmap(df, annot=True, annot_kws={\"size\": 10},fmt=\"f\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fba6cb04160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgT4eG1EJzkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}